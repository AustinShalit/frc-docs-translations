# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, FIRST
# This file is distributed under the same license as the FIRST Robotics Competition package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: FIRST Robotics Competition 2020\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-08-24 04:10+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:4
msgid "Using Inference Output"
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:6
msgid "The Raspberry Pi writes all detection information to NetworkTables, which can be used by your robot code. Below is a Java example for parsing and using this data."
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:8
msgid "**NetworkTables Format**"
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:10
msgid "``ML`` – The table containing all inference data."
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:12
msgid "``nb_objects`` – the number (double) of detected objects in the current frame."
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:13
msgid "``object_classes`` – a string array of the class names of each object. These are in the same order as the coordinates."
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:14
msgid "``boxes`` – a double array containing the coordinates of every detected object. The coordinates are in the following format: [top_left__x1, top_left_y1, bottom_right_x1, bottom_right_y1, top_left_x2, top_left_y2, ... ]. There are four coordinates per box. A way to parse this array in Java is shown below."
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:16
msgid "The below ``VisionSubsystem`` Java class parses the data from NetworkTables and stores it in a usable way."
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:18
#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:24
msgid "Example code coming soon!"
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:20
#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:26
msgid "Todo"
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:20
#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:26
msgid "Code example should be in allwpilib"
msgstr ""

#: ../../frc-docs/source/docs/software/examples-tutorials/machine-learning/using-inference-output.rst:22
msgid "Using the arrays created by the ``VisionSubsystem``, one can make a simple command to turn to face a game piece. In this example, a hatch is used. One thing to note is the ~15fps of inference attained by a Google Coral is not fast enough for PID input directly, however calculating the relative heading of a game piece and then turning to that heading works accurately."
msgstr ""
